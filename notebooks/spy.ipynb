{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "\n",
    "import importlib\n",
    "\n",
    "from src.datasets.huge_stock_ds import spy\n",
    "from src.models import basic_dnn_regression\n",
    "importlib.reload(spy)\n",
    "importlib.reload(basic_dnn_regression)\n",
    "\n",
    "data_dir = \"../data/kaggle-huge-stock-market-dataset\"\n",
    "etfs = os.path.join(data_dir, \"ETFs\")\n",
    "\n",
    "ds = spy.SPYDataset(data_dir, ['Open'], 'Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "train_ds, test_ds = data.random_split(ds, [int(0.8*len(ds)), len(ds)-int(0.8*len(ds))])\n",
    "train_dl = data.DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=256, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "net = basic_dnn_regression.BasicDNNRegression()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch #: 10, Current Loss: 15372.296, Avg Loss: 19046.283: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s]\n",
      "Epoch: 2, Batch #: 10, Current Loss: 8482.211, Avg Loss: 11095.933: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s]\n",
      "Epoch: 3, Batch #: 10, Current Loss: 3873.439, Avg Loss: 5783.653: 100%|██████████| 10/10 [00:01<00:00,  5.02it/s]\n",
      "Epoch: 4, Batch #: 10, Current Loss: 1262.683, Avg Loss: 2253.802: 100%|██████████| 10/10 [00:01<00:00,  5.06it/s]\n",
      "Epoch: 5, Batch #: 10, Current Loss: 111.044, Avg Loss: 467.419: 100%|██████████| 10/10 [00:01<00:00,  5.03it/s]\n",
      "Epoch: 6, Batch #: 10, Current Loss: 19.331, Avg Loss: 18.262: 100%|██████████| 10/10 [00:01<00:00,  5.05it/s]\n",
      "Epoch: 7, Batch #: 10, Current Loss: 55.353, Avg Loss: 48.702: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s]\n",
      "Epoch: 8, Batch #: 10, Current Loss: 16.975, Avg Loss: 35.027: 100%|██████████| 10/10 [00:01<00:00,  5.03it/s]\n",
      "Epoch: 9, Batch #: 10, Current Loss: 1.074, Avg Loss: 5.240: 100%|██████████| 10/10 [00:02<00:00,  4.94it/s]\n",
      "Epoch: 10, Batch #: 10, Current Loss: 2.994, Avg Loss: 1.981: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    net.train_one_epoch(train_dl, optimizer, loss_fn, epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch #: 3, Current Loss: 2.953, Avg Loss: 3.010: 100%|██████████| 3/3 [00:00<00:00,  5.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "3.0103448232014975"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.test(test_dl, criterion=loss_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "feat, labels = next(iter(test_dl))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "feat, labels = feat.to('cuda'), labels.to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[130.1010],\n        [ 89.9163],\n        [103.0305],\n        [105.0759],\n        [104.8373],\n        [ 78.1398],\n        [ 98.1921],\n        [148.1775],\n        [113.1793],\n        [ 67.6154],\n        [185.3016],\n        [209.7485],\n        [100.9795],\n        [146.1898],\n        [104.3937],\n        [ 78.8255],\n        [119.1980],\n        [100.9795],\n        [112.3793],\n        [ 65.6311],\n        [197.7244],\n        [129.2181],\n        [115.7335],\n        [126.6396],\n        [ 85.5871],\n        [149.2773],\n        [ 99.1960],\n        [ 96.5341],\n        [ 79.1922],\n        [184.9490],\n        [106.4334],\n        [ 98.7599],\n        [181.6030],\n        [208.2441],\n        [117.4804],\n        [117.9064],\n        [109.7933],\n        [117.0232],\n        [112.6875],\n        [178.9949],\n        [208.2441],\n        [ 92.4016],\n        [ 66.4983],\n        [182.4958],\n        [121.1076],\n        [194.3703],\n        [182.8357],\n        [115.9616],\n        [163.2944],\n        [125.2191],\n        [129.3311],\n        [192.3816],\n        [124.7903],\n        [173.1716],\n        [128.0995],\n        [101.9129],\n        [105.3979],\n        [ 74.2399],\n        [172.2022],\n        [107.0541],\n        [195.8588],\n        [123.0950],\n        [199.1840],\n        [148.8977],\n        [165.8596],\n        [121.8582],\n        [ 78.9993],\n        [109.3579],\n        [110.4645],\n        [126.6396],\n        [110.7029],\n        [252.3080],\n        [121.4698],\n        [103.9088],\n        [109.7283],\n        [241.0425],\n        [189.4081],\n        [111.9405],\n        [110.4000],\n        [209.1135],\n        [197.1036],\n        [115.5307],\n        [188.3408],\n        [109.0393],\n        [111.6966],\n        [ 95.5446],\n        [112.4555],\n        [209.7485],\n        [231.2462],\n        [101.7764],\n        [124.0178],\n        [127.7493],\n        [109.0393],\n        [148.6757],\n        [181.0088],\n        [ 92.9414],\n        [178.9949],\n        [211.0586],\n        [116.3418],\n        [197.7244],\n        [186.3156],\n        [106.2455],\n        [125.8961],\n        [108.7696],\n        [196.3323],\n        [184.5800],\n        [131.9425],\n        [202.4064],\n        [121.0646],\n        [ 99.3785],\n        [116.0542],\n        [110.0873],\n        [143.5982],\n        [106.0577],\n        [ 96.0400],\n        [198.6803],\n        [ 97.0235],\n        [240.0671],\n        [104.6329],\n        [123.3273],\n        [104.0903],\n        [ 96.9736],\n        [169.3507],\n        [111.2658],\n        [132.2025],\n        [193.6161],\n        [122.4885],\n        [137.2679],\n        [ 98.3981],\n        [102.2397],\n        [111.2658],\n        [114.2383],\n        [241.5675],\n        [167.0286],\n        [109.1570],\n        [100.2426],\n        [193.4628],\n        [189.5475],\n        [ 78.9410],\n        [104.7159],\n        [106.9435],\n        [149.6769],\n        [220.1031],\n        [109.0393],\n        [196.2247],\n        [126.8618],\n        [181.1440],\n        [120.9922],\n        [111.9405],\n        [202.7943],\n        [123.1617],\n        [130.8395],\n        [107.4827],\n        [181.7483],\n        [132.0798],\n        [176.9084],\n        [110.2729],\n        [113.8083],\n        [104.8373],\n        [209.1135],\n        [112.2875],\n        [197.4534],\n        [198.4603],\n        [129.1039],\n        [ 96.2835],\n        [132.2025],\n        [ 92.0721],\n        [193.0166],\n        [183.4993],\n        [102.8466],\n        [184.0713],\n        [131.2366],\n        [ 99.3785],\n        [132.8156],\n        [114.0544],\n        [105.1407],\n        [197.3535],\n        [244.5108],\n        [181.8721],\n        [197.3535],\n        [126.4420],\n        [242.8920],\n        [130.4572],\n        [237.3093],\n        [ 78.1964],\n        [196.8333],\n        [221.7520],\n        [153.8633],\n        [ 97.8267],\n        [241.8137],\n        [189.1913],\n        [169.4741],\n        [210.9795],\n        [194.8451],\n        [225.6950],\n        [110.2729],\n        [ 75.1058],\n        [ 99.3785],\n        [127.5071],\n        [110.5243],\n        [185.9334],\n        [151.1489],\n        [177.5445],\n        [200.5464],\n        [117.1480],\n        [106.2455],\n        [127.3766],\n        [115.8533],\n        [112.2655],\n        [ 84.3368],\n        [200.7108],\n        [128.9822],\n        [194.9662],\n        [231.3805],\n        [104.0287],\n        [103.5301],\n        [120.3190],\n        [169.2317],\n        [254.6954],\n        [153.1215],\n        [ 88.7926],\n        [125.0106],\n        [ 75.6033],\n        [109.3579],\n        [103.9088],\n        [161.5654],\n        [ 98.3981],\n        [190.4075],\n        [240.1915],\n        [146.5662],\n        [148.8143],\n        [113.7503],\n        [130.8395],\n        [190.2849],\n        [198.2011],\n        [111.4403],\n        [184.2054],\n        [122.9157],\n        [108.1698],\n        [112.1427],\n        [114.0097],\n        [ 92.5578],\n        [132.4461],\n        [128.0995],\n        [109.4692],\n        [ 81.2321],\n        [105.6820],\n        [114.9925],\n        [ 93.4491],\n        [209.6001],\n        [102.2397],\n        [215.3225],\n        [148.2827],\n        [130.3478],\n        [141.4879],\n        [118.6271]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[130.3100],\n        [ 90.8810],\n        [102.9400],\n        [105.6100],\n        [104.6500],\n        [ 79.2080],\n        [100.0300],\n        [150.9000],\n        [115.3000],\n        [ 65.0310],\n        [188.4600],\n        [210.9200],\n        [102.1400],\n        [147.2800],\n        [103.2700],\n        [ 81.6890],\n        [121.0100],\n        [101.9300],\n        [113.7100],\n        [ 66.2860],\n        [199.7400],\n        [130.9900],\n        [116.5900],\n        [128.3000],\n        [ 87.4730],\n        [151.7100],\n        [ 99.5500],\n        [ 97.1350],\n        [ 80.3400],\n        [186.2400],\n        [107.8800],\n        [ 99.7200],\n        [183.2200],\n        [210.8300],\n        [118.8100],\n        [119.5700],\n        [111.9700],\n        [118.0000],\n        [113.7600],\n        [181.5000],\n        [209.6000],\n        [ 93.3530],\n        [ 66.0860],\n        [184.5000],\n        [122.2800],\n        [194.3500],\n        [184.7400],\n        [117.0800],\n        [164.3200],\n        [126.2400],\n        [131.4200],\n        [197.2800],\n        [126.0100],\n        [175.2100],\n        [129.0100],\n        [ 98.6980],\n        [106.9300],\n        [ 73.1340],\n        [174.2600],\n        [108.9100],\n        [198.8700],\n        [124.4000],\n        [203.0200],\n        [150.9700],\n        [167.3500],\n        [124.8100],\n        [ 78.1180],\n        [109.6500],\n        [111.4100],\n        [128.2300],\n        [112.0100],\n        [254.6200],\n        [122.5800],\n        [106.0700],\n        [110.9000],\n        [244.3500],\n        [191.2300],\n        [113.9500],\n        [111.5000],\n        [210.7700],\n        [198.9100],\n        [114.8300],\n        [187.6300],\n        [109.8700],\n        [112.3600],\n        [ 96.8360],\n        [113.3800],\n        [210.4300],\n        [233.5400],\n        [103.4100],\n        [125.4700],\n        [127.6900],\n        [110.6600],\n        [150.1600],\n        [183.8700],\n        [ 94.1090],\n        [178.8400],\n        [212.6300],\n        [115.0500],\n        [199.1800],\n        [187.9300],\n        [107.4200],\n        [127.3400],\n        [110.9100],\n        [199.7800],\n        [185.4200],\n        [132.9200],\n        [203.7800],\n        [120.4500],\n        [ 99.2000],\n        [117.2100],\n        [110.2900],\n        [145.3800],\n        [107.0200],\n        [ 97.4670],\n        [200.7900],\n        [ 97.7450],\n        [241.7600],\n        [105.4900],\n        [124.5900],\n        [105.3200],\n        [ 97.6850],\n        [170.9100],\n        [111.1500],\n        [133.3500],\n        [195.6900],\n        [124.6500],\n        [139.3600],\n        [ 99.8500],\n        [103.8700],\n        [112.2400],\n        [114.9600],\n        [243.3600],\n        [165.9300],\n        [110.3200],\n        [101.5800],\n        [195.2900],\n        [191.8500],\n        [ 80.6100],\n        [105.4600],\n        [107.7300],\n        [150.2400],\n        [222.3600],\n        [110.1300],\n        [196.2500],\n        [127.6700],\n        [183.8000],\n        [122.7900],\n        [113.0900],\n        [205.5900],\n        [125.2200],\n        [132.1600],\n        [108.3100],\n        [181.5100],\n        [132.8100],\n        [178.3000],\n        [111.3800],\n        [114.8800],\n        [105.9200],\n        [211.8600],\n        [113.5000],\n        [201.0200],\n        [201.1100],\n        [129.4200],\n        [ 96.0890],\n        [130.4000],\n        [ 93.4370],\n        [194.9900],\n        [185.1800],\n        [103.2600],\n        [186.5300],\n        [132.6300],\n        [100.8400],\n        [133.9600],\n        [114.5100],\n        [106.4900],\n        [198.0500],\n        [245.9800],\n        [183.4300],\n        [199.0300],\n        [127.6100],\n        [242.5600],\n        [132.4100],\n        [239.0900],\n        [ 78.9000],\n        [200.4900],\n        [224.3300],\n        [155.4600],\n        [ 98.9860],\n        [243.3700],\n        [191.3300],\n        [171.0700],\n        [212.6100],\n        [194.6700],\n        [228.2600],\n        [112.0000],\n        [ 75.8790],\n        [100.5500],\n        [128.5700],\n        [109.8400],\n        [186.5900],\n        [152.2300],\n        [176.2600],\n        [202.3200],\n        [118.4200],\n        [107.5100],\n        [129.8800],\n        [117.1300],\n        [113.4400],\n        [ 85.2770],\n        [202.4000],\n        [129.9700],\n        [199.0100],\n        [234.4600],\n        [104.4600],\n        [105.7700],\n        [120.6900],\n        [171.3000],\n        [256.7500],\n        [155.0900],\n        [ 89.8790],\n        [124.6100],\n        [ 77.5080],\n        [110.2700],\n        [104.6400],\n        [163.4500],\n        [ 99.0060],\n        [193.3300],\n        [244.2300],\n        [145.5900],\n        [150.7300],\n        [115.4100],\n        [129.8900],\n        [192.1100],\n        [198.6700],\n        [111.6400],\n        [185.3100],\n        [123.2700],\n        [110.4600],\n        [113.6100],\n        [115.8200],\n        [ 92.9710],\n        [133.6200],\n        [129.8600],\n        [111.3400],\n        [ 81.5850],\n        [106.3600],\n        [114.8500],\n        [ 95.2370],\n        [211.5000],\n        [102.3700],\n        [216.0100],\n        [150.4900],\n        [131.0400],\n        [141.6600],\n        [121.0000]], device='cuda:0')"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}